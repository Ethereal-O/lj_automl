import sys
import os
import itertools
from collections import defaultdict

# ==========================================
# 0. åŠ è½½ç¯å¢ƒä¸é…ç½®
# ==========================================
try:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)

    from adapters.field_config import field_config
    from adapters.dic_lol import result_dict as FIELD_META
    
    # 1. è·å–ç¯å¢ƒå®é™…ä½¿ç”¨çš„å­—æ®µ (695ä¸ª)
    ENV_FIELDS = set(field_config.get_field_names())
    
    # å»ºç«‹æ¨¡ç³Šç´¢å¼• (å»æ‰FeatureåŒ…è£…ã€å»æ‰ä¸‹åˆ’çº¿ã€å¿½ç•¥å¤§å°å†™)
    # ç›®çš„ï¼šä¸ºäº†è¯†åˆ«é‚£äº›ä»…ä»…æ˜¯åå­—å†™æ³•ä¸åŒï¼Œä½†å®é™…ä¸Šå­˜åœ¨çš„å­—æ®µ
    def normalize(name):
        s = name.replace("Feature(", "").replace(")", "").strip()
        s = s.replace("_", "").replace(".", "").lower()
        return s

    ENV_INDEX = {normalize(f) for f in ENV_FIELDS}

except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# ==========================================
# 1. ç”Ÿæˆå…¨é‡å­—å…¸ (1744ä¸ª)
# ==========================================
def generate_full_dict():
    full_list = []
    for tmpl_key, (tmpl_type, tmpl_options_groups) in FIELD_META.items():
        if not tmpl_options_groups:
            full_list.append(tmpl_key)
            continue
        
        format_str = tmpl_key.replace('_', '{}')
        try:
            # å…¼å®¹å¤„ç†
            clean_groups = []
            for g in tmpl_options_groups:
                if isinstance(g, list): clean_groups.append([str(x) for x in g])
                else: clean_groups.append([str(g)])
            
            for combination in itertools.product(*clean_groups):
                try:
                    full_list.append(format_str.format(*combination))
                except: pass
        except: pass
    return full_list

# ==========================================
# 2. æ ¸å¿ƒåˆ†æé€»è¾‘
# ==========================================
def analyze_reduction():
    print("ğŸš€ å¼€å§‹åˆ†æå­—æ®µç­›é€‰é€»è¾‘...")
    
    # A. ç”Ÿæˆæ€»é›†
    FULL_DICT_LIST = generate_full_dict()
    print(f"ğŸ“š å­—å…¸ç†è®ºå…¨é›†: {len(FULL_DICT_LIST)} ä¸ª")
    print(f"ğŸŒ ç¯å¢ƒå®é™…è£…è½½: {len(ENV_FIELDS)} ä¸ª")
    
    # B. æ‰¾å‡ºè¢«ä¸¢å¼ƒçš„å­—æ®µ (Rejected)
    # é€»è¾‘ï¼šå¦‚æœå­—å…¸é‡Œçš„å­—æ®µï¼Œnormalizeåä¸åœ¨ç¯å¢ƒé‡Œï¼Œé‚£å°±æ˜¯çœŸè¢«ä¸¢äº†
    kept_count = 0
    rejected_list = []
    
    for field in FULL_DICT_LIST:
        norm = normalize(field)
        if norm in ENV_INDEX:
            kept_count += 1
        else:
            rejected_list.append(field)
            
    print(f"âœ… ä¿ç•™å­—æ®µ (Kept): {kept_count} ä¸ª")
    print(f"ğŸ—‘ï¸ è¢«ä¸¢å¼ƒ/æœªåŠ è½½ (Dropped): {len(rejected_list)} ä¸ª")
    
    if len(rejected_list) == 0:
        print("ğŸ‰ å¥‡æ€ªï¼Œæ²¡æœ‰å­—æ®µè¢«ä¸¢å¼ƒï¼Ÿé‚£æ•°é‡åº”è¯¥å¯¹å¾—ä¸Šå•Šã€‚")
        return

    # C. åˆ†æä¸¢å¼ƒè§„å¾‹ (Clustering)
    # æˆ‘ä»¬æŒ‰å‰ç¼€åˆ†ç»„ï¼Œçœ‹çœ‹å“ªç±»å­—æ®µæ­»ä¼¤æƒ¨é‡
    print("\nğŸ” [ä¸¢å¼ƒè§„å¾‹åˆ†æ] çœ‹çœ‹æ˜¯è°è¢«åˆ äº†ï¼š")
    
    category_stats = defaultdict(lambda: {"total": 0, "dropped": 0, "examples": []})
    
    for f in FULL_DICT_LIST:
        prefix = f.split('.')[0] # è·å– Preload, CS, Slice
        category_stats[prefix]["total"] += 1
        
        norm = normalize(f)
        if norm not in ENV_INDEX:
            category_stats[prefix]["dropped"] += 1
            if len(category_stats[prefix]["examples"]) < 3:
                category_stats[prefix]["examples"].append(f)

    # æ‰“å°åˆ†ç»„ç»Ÿè®¡
    print("-" * 60)
    print(f"{'ç±»åˆ«':<10} | {'æ€»æ•°':<8} | {'ä¸¢å¼ƒæ•°':<8} | {'ä¸¢å¼ƒç‡':<8} | {'ä¸¢å¼ƒç¤ºä¾‹'}")
    print("-" * 60)
    
    for prefix, stats in category_stats.items():
        rate = (stats["dropped"] / stats["total"]) * 100
        examples = ", ".join(stats["examples"])
        print(f"{prefix:<10} | {stats['total']:<8} | {stats['dropped']:<8} | {rate:6.1f}% | {examples}...")

    # D. æ·±åº¦ç‰¹å¾åˆ†æ (çŒœæµ‹æ˜¯å¦è¿‡æ»¤äº†ç‰¹å®šåç¼€)
    # æ¯”å¦‚ï¼šæ˜¯ä¸æ˜¯æ‰€æœ‰çš„ 'Sell' éƒ½è¢«ä¸¢äº†ï¼Ÿæˆ–è€…æ‰€æœ‰çš„ 'Vol'ï¼Ÿ
    print("\nğŸ•µï¸ [æ·±åº¦ç‰¹å¾ä¾¦æ¢] å…³é”®è¯å‘½ä¸­ç‡åˆ†æ:")
    keywords = ["Buy", "Sell", "Amt", "Vol", "Cnt", "1min", "5min", "Ret", "Res"]
    
    print(f"{'å…³é”®è¯':<10} | {'è¢«ä¸¢å¼ƒçš„å­—æ®µé‡ŒåŒ…å«æ­¤è¯çš„æ•°é‡'}")
    for kw in keywords:
        count = sum(1 for f in rejected_list if kw in f)
        if count > 0:
            print(f"{kw:<10} | {count}")

if __name__ == "__main__":
    analyze_reduction()