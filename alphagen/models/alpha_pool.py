from itertools import count
import math
from typing import List, Optional, Tuple, Set
from abc import ABCMeta, abstractmethod

import numpy as np
import torch
from torch import Tensor
from alphagen.data.calculator import AlphaCalculator

from alphagen.data.expression import Expression
from alphagen.utils.correlation import batch_pearsonr, batch_spearmanr
from alphagen.utils.pytorch_utils import masked_mean_std
from alphagen_qlib.stock_data import StockData

# å¯¼å…¥å› å­ç¼“å­˜
from adapters.scoring_calculator import factor_cache


class AlphaPoolBase(metaclass=ABCMeta):
    def __init__(
        self,
        capacity: int,
        calculator: AlphaCalculator,
        device: torch.device = torch.device('cpu')
    ):
        self.capacity = capacity
        self.calculator = calculator
        self.device = device

    @abstractmethod
    def to_dict(self) -> dict: ...

    @abstractmethod
    def try_new_expr(self, expr: Expression) -> float: ...

    @abstractmethod
    def test_ensemble(self, calculator: AlphaCalculator) -> Tuple[float, float]: ...


class AlphaPool(AlphaPoolBase):
    def __init__(
        self,
        capacity: int,
        calculator: AlphaCalculator,
        ic_lower_bound: Optional[float] = None,
        l1_alpha: float = 5e-3,
        device: torch.device = torch.device('cpu'),
        enable_culling: bool = False,  # Whether to enable pool culling
        culling_method: str = 'ic_drop',  # 'ic_drop', 'weight', or 'combined'
        baseline_expressions: Optional[List[str]] = None,  # åŸºå‡†å› å­è¡¨è¾¾å¼åˆ—è¡¨
        use_lgb_evaluation: bool = False,  # æ˜¯å¦ä½¿ç”¨LightGBMè¯„ä¼°ç»„åˆæ•ˆæœ
        reeval_cycle: int = 1000,  # é‡æ–°è¯„ä¼°å‘¨æœŸï¼ˆæ¯å¤šå°‘ä¸ªå› å­ï¼‰
        reeval_q5_threshold: float = 0.5  # q5æå‡é˜ˆå€¼ï¼ˆbpsï¼‰
    ):
        super().__init__(capacity, calculator, device)

        self.size: int = 0
        self.exprs: List[Optional[Expression]] = [None for _ in range(capacity + 1)]
        self.single_ics: np.ndarray = np.zeros(capacity + 1)
        self.mutual_ics: np.ndarray = np.identity(capacity + 1)
        self.weights: np.ndarray = np.zeros(capacity + 1)
        self.best_ic_ret: float = -1.

        self.ic_lower_bound = ic_lower_bound or -1.
        self.l1_alpha = l1_alpha
        self.enable_culling = enable_culling
        self.culling_method = culling_method
        self.baseline_expressions = baseline_expressions or []
        self.use_lgb_evaluation = use_lgb_evaluation

        # æ–°å¢ï¼šé‡æ–°è¯„ä¼°ç›¸å…³å‚æ•°
        self.reeval_cycle = reeval_cycle
        self.reeval_q5_threshold = reeval_q5_threshold

        self.eval_cnt = 0
        self._prev_metrics = None  # å­˜å‚¨ä¸Šä¸€æ¬¡çš„è¯„ä¼°æŒ‡æ ‡

        # å››æ± ç®¡ç†ç³»ç»Ÿ
        self.premium_factors: List[Tuple[str, float]] = []  # é«˜è´µå› å­ï¼š(è¡¨è¾¾å¼, IC)
        self.lgb_factors: List[Tuple[str, float]] = []      # LGBå› å­ï¼š(è¡¨è¾¾å¼, ç»„åˆè´¡çŒ®)
        self.staged_factors: List[Tuple[str, float]] = []   # æš‚å­˜å› å­ï¼š(è¡¨è¾¾å¼, å•å› å­IC)
        self.discarded_factors: List[Tuple[str, float]] = [] # ä¸¢å¼ƒå› å­ï¼š(è¡¨è¾¾å¼, å•å› å­IC)

        # æ± å­å®¹é‡
        self.premium_pool_capacity = capacity // 2  # é«˜è´µå› å­æ± å®¹é‡
        self.lgb_pool_capacity = capacity          # LGBå› å­æ± å®¹é‡
        self.staged_pool_capacity = capacity       # æš‚å­˜å› å­æ± å®¹é‡

        # é«˜è´µå› å­ç®¡ç†
        self.pending_premium_factors: List[Tuple[str, float]] = []  # æ–°å¢é«˜è´µå› å­ï¼Œæš‚æ—¶ä¸å‚ä¸LGB
        self.active_premium_factors: List[Tuple[str, float]] = []   # å‚ä¸LGBè®¡ç®—çš„é«˜è´µå› å­
        self.staged_cleanup_count = 0  # æš‚å­˜æ± æ¸…ç†æ¬¡æ•°è®¡æ•°å™¨
        self.premium_graduation_threshold = 5  # æ¯5æ¬¡æš‚å­˜æ± æ¸…ç†ï¼Œæ›´æ–°ä¸€æ¬¡é«˜è´µå› å­å‚ä¸çŠ¶æ€

        # LGBè¯„ä¼°ç›¸å…³
        self.current_lgb_baseline = None  # å½“å‰LGB baseline metrics
        self.staged_evaluation_multiplier = 2.0  # æš‚å­˜å› å­æˆåŠŸåŠ å…¥çš„å¥–åŠ±ä¹˜æ•°
        self._pending_staged_rewards = {}  # æš‚å­˜å› å­çš„åŸºç¡€å¥–åŠ±è®°å½•
        self._staged_episode_info = {}  # æš‚å­˜å› å­çš„episodeä¿¡æ¯ï¼Œç”¨äºå»¶è¿Ÿå¥–åŠ±
        self._resolved_rewards = {}  # å·²è§£å†³çš„å»¶è¿Ÿå¥–åŠ±

        # è¯„ä¼°è®¡æ•°å™¨
        self.last_reeval_cnt = 0
        self.last_premium_update = 0  # é«˜è´µå› å­æ›´æ–°è®¡æ•°å™¨
        self.premium_update_cycle = 1000  # é«˜è´µå› å­æ›´æ–°å‘¨æœŸ

    @property
    def state(self) -> dict:
        return {
            "exprs": list(self.exprs[:self.size]),
            "ics_ret": list(self.single_ics[:self.size]),
            "weights": list(self.weights[:self.size]),
            "best_ic_ret": self.best_ic_ret
        }

    def to_dict(self) -> dict:
        return {
            "exprs": [str(expr) for expr in self.exprs[:self.size]],
            "weights": list(self.weights[:self.size])
        }

    def try_new_expr(self, expr: Expression) -> float:
        """å°è¯•æ·»åŠ æ–°è¡¨è¾¾å¼ï¼Œè¿”å›å¥–åŠ±å€¼"""
        expr_str = str(expr)
        self.eval_cnt += 1

        # ===== æ£€æŸ¥æ˜¯å¦å¤„äºé¢„çƒ­é˜¶æ®µ =====
        # å¦‚æœæœ‰agentå¼•ç”¨ä¸”memoryæœªæ»¡ï¼Œç›´æ¥è¿”å›0å¥–åŠ±ï¼Œä¸è¿›è¡ŒICè®¡ç®—
        if hasattr(self.calculator, '_agent_ref') and self.calculator._agent_ref():
            agent = self.calculator._agent_ref()
            # æ£€æŸ¥å¤šç§memoryè¡¨ç¤ºæ–¹å¼
            memory_size = 0
            if hasattr(agent, 'memory'):
                if hasattr(agent.memory, 'size'):
                    memory_size = agent.memory.size()
                elif hasattr(agent.memory, '__len__'):
                    memory_size = len(agent.memory)
                elif hasattr(agent.memory, '_buffer'):
                    memory_size = len(agent.memory._buffer) if hasattr(agent.memory, '_buffer') else 0

            if memory_size < 10000:
                # é¢„çƒ­é˜¶æ®µï¼šmemoryæœªæ»¡ï¼Œä¸è®¡ç®—çœŸå®ICï¼Œç›´æ¥è¿”å›0
                return 0.0

        # ===== ç¬¬ä¸€æ­¥ï¼šå¼‚æ­¥è®¡ç®—å•å› å­IC =====
        try:
            single_ic = self.calculator.calc_single_IC_ret(expr)
            ic_threshold = max(self.ic_lower_bound, 0.01)  # æœ€ä½ICé˜ˆå€¼
            passes_single_test = not np.isnan(single_ic) and abs(single_ic) >= ic_threshold
        except Exception as e:
            print(f"Error calculating single IC for {expr_str}: {e}")
            single_ic = 0.0
            passes_single_test = False

        # ===== ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»åœ¨LGBæ± ä¸­ï¼ˆå¥–åŠ±è†¨èƒ€ï¼‰=====
        is_in_lgb_pool = any(expr == expr_str for expr, _ in self.lgb_factors)

        # ===== ç¬¬ä¸‰æ­¥ï¼šæ ¹æ®ICåˆ†æµåˆ°ä¸åŒæ± å­ =====
        if passes_single_test:
            # ğŸ¯ é«˜è´µå› å­ï¼šå•å› å­ICè¶³å¤Ÿé«˜
            self.pending_premium_factors.append((expr_str, single_ic))
            reward = self._calculate_ic_reward(single_ic)  # å•å› å­ICå¥–åŠ±
            # å¦‚æœå·²ç»åœ¨LGBæ± ä¸­ï¼Œå¥–åŠ±è†¨èƒ€
            if is_in_lgb_pool:
                reward *= self.staged_evaluation_multiplier

        else:
            # ğŸ“¦ æš‚å­˜å› å­ï¼šç­‰å¾…ç»„åˆè¯„ä¼°ï¼Œå¥–åŠ±å»¶è¿Ÿç¡®å®š
            self.staged_factors.append((expr_str, single_ic))

            # æš‚å­˜å› å­episodeç»“æŸæ—¶ä¸ç»™äºˆå¥–åŠ±ï¼ˆå»¶è¿Ÿç¡®å®šï¼‰
            reward = 0.0  # ä¸ç”¨äºç½‘ç»œæ›´æ–°

            # è®°å½•æš‚å­˜å› å­çš„episodeä¿¡æ¯ï¼Œç”¨äºåç»­å¥–åŠ±ç¡®å®š
            episode_id = f"episode_{self.eval_cnt}"
            self._staged_episode_info[episode_id] = {
                'expr_str': expr_str,
                'single_ic': single_ic,
                'base_reward': self._calculate_ic_reward(single_ic),
                'status': 'pending'  # pending, discarded, promoted
            }

        # ===== ç¬¬ä¸‰æ­¥ï¼šå¤„ç†é«˜è´µå› å­åŠ å…¥ =====
        self._process_pending_premium_factors()

        # ===== ç¬¬å››æ­¥ï¼šæ£€æŸ¥æš‚å­˜æ± æ˜¯å¦éœ€è¦è¯„ä¼° =====
        available_slots = self.staged_pool_capacity - len(self.staged_factors)
        if available_slots <= 0:
            # æš‚å­˜æ± æ»¡äº†ï¼Œå¼€å§‹è¯„ä¼°
            self._evaluate_staged_factors()

        # ===== ç¬¬äº”æ­¥ï¼šå®šæœŸæ›´æ–°é«˜è´µå› å­å‚ä¸çŠ¶æ€ =====
        if self.eval_cnt - self.last_premium_update >= self.premium_update_cycle:
            self._update_premium_participation()

        return reward

    def _calculate_ic_reward(self, ic: float) -> float:
        """è®¡ç®—åŸºäºå•å› å­ICçš„å¥–åŠ±ï¼ˆéçº¿æ€§æ”¾å¤§é«˜ICï¼‰"""
        return max(ic ** 2 * 2.0, 0.0)  # ICçš„å¹³æ–¹ä½œä¸ºå¥–åŠ±ï¼Œæ›´åå¥½é«˜IC

    def _calculate_staged_reward(self, base_ic: float) -> float:
        """è®¡ç®—æš‚å­˜å› å­æˆåŠŸåŠ å…¥çš„å¥–åŠ±ï¼ˆå¸¦ä¹˜æ•°ï¼‰"""
        return self._calculate_ic_reward(base_ic) * self.staged_evaluation_multiplier

    def _find_worst_factor_idx(self) -> int:
        """æ‰¾åˆ°æœ€å·®å› å­çš„ç´¢å¼•"""
        if self.culling_method == 'weight':
            return np.argmin(np.abs(self.weights[:self.size]))
        elif self.culling_method == 'ic':
            return np.argmin(np.abs(self.single_ics[:self.size]))
        else:  # é»˜è®¤ä½¿ç”¨æƒé‡
            return np.argmin(np.abs(self.weights[:self.size]))

    def _process_pending_premium_factors(self):
        """å¤„ç†ç­‰å¾…åŠ å…¥çš„é«˜è´µå› å­"""
        if not self.pending_premium_factors:
            return

        # ç›´æ¥åŠ å…¥é«˜è´µå› å­æ± ï¼ˆæ‰€æœ‰é€šè¿‡ç­›é€‰çš„éƒ½ä¿ç•™ï¼‰
        for expr_str, ic in self.pending_premium_factors:
            self.premium_factors.append((expr_str, ic))


        self.pending_premium_factors.clear()

    def _evaluate_staged_factors(self):
        """è¯„ä¼°æš‚å­˜å› å­æ± ï¼Œä½¿ç”¨LGBè¯„ä¼°ç»„åˆæ•ˆæœ"""
        from adapters.scoring_calculator import evaluate_factor_combination_lgb

        if not self.staged_factors:
            return

        # è·å–å½“å‰å‚ä¸LGBè®¡ç®—çš„å› å­ï¼šå‚ä¸è®¡ç®—çš„é«˜è´µå› å­ + LGBå› å­
        active_premium_exprs = [expr for expr, _ in self.active_premium_factors]  # å½“å‰å‚ä¸LGBçš„é«˜è´µå› å­
        lgb_exprs = [expr for expr, _ in self.lgb_factors]

        # æ„å»ºå½“å‰baselineï¼šå‚ä¸è®¡ç®—çš„é«˜è´µå› å­ + LGBå› å­
        baseline_exprs = active_premium_exprs + lgb_exprs

        # ç¡®ä¿æ‰€æœ‰baselineå› å­çš„å› å­å€¼éƒ½å·²è®¡ç®—
        for expr_str in baseline_exprs:
            if not factor_cache.has_factor(expr_str):
                continue

        # è¯„ä¼°å½“å‰baselineçš„æ€§èƒ½
        baseline_metrics = evaluate_factor_combination_lgb(baseline_exprs, [])
        if "error" in baseline_metrics:
            return

        baseline_q5 = baseline_metrics.get("q5_return_bps", 0.0)

        # é€ä¸ªè¯„ä¼°æš‚å­˜å› å­
        promoted_factors = []
        discarded_factors = []

        for expr_str, single_ic in self.staged_factors:
            # ç¡®ä¿æš‚å­˜å› å­çš„å› å­å€¼å·²è®¡ç®—
            if not factor_cache.has_factor(expr_str):
                discarded_factors.append((expr_str, single_ic))
                continue

            # è¯„ä¼°åŠ å…¥è¿™ä¸ªæš‚å­˜å› å­åçš„ç»„åˆæ€§èƒ½
            test_exprs = baseline_exprs + [expr_str]
            test_metrics = evaluate_factor_combination_lgb(test_exprs, [])

            if "error" in test_metrics:
                discarded_factors.append((expr_str, single_ic))
                continue

            combined_q5 = test_metrics.get("q5_return_bps", 0.0)
            q5_improvement = combined_q5 - baseline_q5

            # å¦‚æœq5æå‡è¶…è¿‡é˜ˆå€¼ï¼ŒåŠ å…¥LGBå› å­æ± 
            if q5_improvement >= self.reeval_q5_threshold:
                promoted_factors.append((expr_str, q5_improvement))
            else:
                discarded_factors.append((expr_str, single_ic))

        # å¤„ç†æå‡çš„å› å­ - å¥–åŠ±ç¡®å®šä¸ºé«˜å¥–åŠ±
        for expr_str, improvement in promoted_factors:
            self.lgb_factors.append((expr_str, improvement))

            # ç¡®å®šå¯¹åº”episodeçš„å¥–åŠ±ï¼šæ¯”é«˜è´µå› å­æ›´å¥½çš„å¥–åŠ±
            for episode_id, episode_info in self._staged_episode_info.items():
                if episode_info['expr_str'] == expr_str and episode_info['status'] == 'pending':
                    # æˆåŠŸåŠ å…¥LGBæ± ï¼šè·å¾—é«˜é¢å¥–åŠ±
                    promoted_reward = self._calculate_staged_reward(episode_info['single_ic'])
                    episode_info['final_reward'] = promoted_reward
                    episode_info['status'] = 'promoted'
                    self._resolved_rewards[episode_id] = promoted_reward
                    print(f"ğŸ† Episode {episode_id} reward resolved: {promoted_reward:.4f} (promoted to LGB)")

            # LGBæ± å®¹é‡ç®¡ç†
            if len(self.lgb_factors) > self.lgb_pool_capacity:
                self.lgb_factors.sort(key=lambda x: x[1])  # æŒ‰è´¡çŒ®æ’åº
                removed = self.lgb_factors.pop(0)
                print(f"ğŸ—‘ï¸ Removed weakest LGB factor: {removed[0]}")

        # å¤„ç†ä¸¢å¼ƒçš„å› å­ - å¥–åŠ±ç¡®å®šä¸ºæ™®é€šICå¥–åŠ±
        for expr_str, single_ic in discarded_factors:
            # ç¡®å®šå¯¹åº”episodeçš„å¥–åŠ±ï¼šå’Œé«˜è´µå› å­ä¸€æ ·çš„å¥–åŠ±
            for episode_id, episode_info in self._staged_episode_info.items():
                if episode_info['expr_str'] == expr_str and episode_info['status'] == 'pending':
                    # è¢«ä¸¢å¼ƒï¼šè·å¾—æ™®é€šICå¥–åŠ±
                    discarded_reward = self._calculate_ic_reward(single_ic)
                    episode_info['final_reward'] = discarded_reward
                    episode_info['status'] = 'discarded'
                    self._resolved_rewards[episode_id] = discarded_reward
                    print(f"ğŸ—‘ï¸ Episode {episode_id} reward resolved: {discarded_reward:.4f} (discarded)")

        # è®°å½•ä¸¢å¼ƒçš„å› å­åˆ°ä¸¢å¼ƒæ± 
        self.discarded_factors.extend(discarded_factors)

        # æš‚å­˜æ± æ¸…ç†è®¡æ•°å™¨+1
        self.staged_cleanup_count += 1

        # æ¸…ç©ºæš‚å­˜æ± 
        self.staged_factors.clear()

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°é«˜è´µå› å­å‚ä¸çŠ¶æ€
        if self.staged_cleanup_count % self.premium_graduation_threshold == 0:
            self._update_premium_participation()

    def _update_premium_participation(self):
        """å®šæœŸæ›´æ–°é«˜è´µå› å­å‚ä¸LGBè®¡ç®—çš„çŠ¶æ€"""
        print(f"ğŸ”„ Updating premium factor participation status...")

        # æ‰€æœ‰é«˜è´µå› å­éƒ½å¼€å§‹å‚ä¸LGBè®¡ç®—ï¼ˆ"æ¯•ä¸š"ï¼‰
        self.active_premium_factors = self.premium_factors.copy()

        print(f"âœ… All {len(self.active_premium_factors)} premium factors now active in LGB evaluation")

        # é‡æ–°è®¡ç®—LGB baselineï¼šæ–°åŠ å…¥çš„é«˜è´µ + æ—§é«˜è´µï¼ˆå·²å‚ä¸çš„ï¼‰ + æœ€æ–°LGBå› å­
        from adapters.scoring_calculator import evaluate_factor_combination_lgb

        baseline_exprs = [expr for expr, _ in self.active_premium_factors + self.lgb_factors]

        # ç¡®ä¿æ‰€æœ‰baselineå› å­çš„å› å­å€¼éƒ½å·²è®¡ç®—
        for expr_str in baseline_exprs:
            if not factor_cache.has_factor(expr_str):
                print(f"âš ï¸  Premium factor {expr_str} not in cache, skipping...")
                continue

        # é‡æ–°è¯„ä¼°baseline
        baseline_metrics = evaluate_factor_combination_lgb(baseline_exprs, [])
        if "error" in baseline_metrics:
            print(f"âŒ Failed to update baseline: {baseline_metrics.get('error', 'Unknown error')}")
        else:
            self.current_lgb_baseline = baseline_metrics
            baseline_q5 = baseline_metrics.get("q5_return_bps", 0.0)
            print(f"ğŸ“Š Updated LGB baseline q5: {baseline_q5:.2f} bps")

        self.last_premium_update = self.eval_cnt

    def _add_factor_to_pool(self, expr: Expression):
        """æ·»åŠ å› å­åˆ°æ± å­ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸è®¡ç®—ICï¼‰"""
        if self.size >= self.capacity:
            if self.enable_culling:
                self._pop()
            else:
                return  # æ± å­å·²æ»¡ï¼Œä¸æ·»åŠ 

        n = self.size
        self.exprs[n] = expr
        self.single_ics[n] = 0.0  # æš‚æ—¶è®¾ä¸º0
        for i in range(n):
            self.mutual_ics[i][n] = self.mutual_ics[n][i] = 0.0
        self.weights[n] = 1.0  # æš‚æ—¶è®¾ä¸º1
        self.size += 1

    def force_load_exprs(self, exprs: List[Expression]) -> None:
        for expr in exprs:
            ic_ret, ic_mut = self._calc_ics(expr, ic_mut_threshold=None)
            assert ic_ret is not None and ic_mut is not None
            self._add_factor(expr, ic_ret, ic_mut)
            assert self.size <= self.capacity
        self._optimize(alpha=self.l1_alpha, lr=5e-4, n_iter=500)

    def _optimize(self, alpha: float, lr: float, n_iter: int) -> np.ndarray:
        if math.isclose(alpha, 0.): # no L1 regularization
            return self._optimize_lstsq() # very fast

        ics_ret = torch.from_numpy(self.single_ics[:self.size]).to(self.device)
        ics_mut = torch.from_numpy(self.mutual_ics[:self.size, :self.size]).to(self.device)
        weights = torch.from_numpy(self.weights[:self.size]).to(self.device).requires_grad_()
        optim = torch.optim.Adam([weights], lr=lr)

        loss_ic_min = 1e9 + 7  # An arbitrary big value
        best_weights = weights.cpu().detach().numpy()
        iter_cnt = 0
        for it in count():
            ret_ic_sum = (weights * ics_ret).sum()
            mut_ic_sum = (torch.outer(weights, weights) * ics_mut).sum()
            loss_ic = mut_ic_sum - 2 * ret_ic_sum + 1
            loss_ic_curr = loss_ic.item()

            loss_l1 = torch.norm(weights, p=1)  # type: ignore
            loss = loss_ic + alpha * loss_l1

            optim.zero_grad()
            loss.backward()
            optim.step()

            if loss_ic_min - loss_ic_curr > 1e-6:
                iter_cnt = 0
            else:
                iter_cnt += 1

            if loss_ic_curr < loss_ic_min:
                best_weights = weights.cpu().detach().numpy()
                loss_ic_min = loss_ic_curr

            if iter_cnt >= n_iter or it >= 10000:
                break

        return best_weights

    def _optimize_lstsq(self) -> np.ndarray:
        try:
            return np.linalg.lstsq(self.mutual_ics[:self.size, :self.size],self.single_ics[:self.size])[0]
        except (np.linalg.LinAlgError, ValueError):
            return self.weights[:self.size]

    def test_ensemble(self, calculator: AlphaCalculator) -> Tuple[float, float]:
        ic = calculator.calc_pool_IC_ret(self.exprs[:self.size], self.weights[:self.size])
        return ic
        # rank_ic = calculator.calc_pool_rIC_ret(self.exprs[:self.size], self.weights[:self.size])
        # return ic, 
        
    def evaluate_ensemble(self) -> float:
        ic = self.calculator.calc_pool_IC_ret(self.exprs[:self.size], self.weights[:self.size])
        return ic

    @property
    def _under_thres_alpha(self) -> bool:
        if self.ic_lower_bound is None or self.size > 1:
            return False
        return self.size == 0 or abs(self.single_ics[0]) < self.ic_lower_bound

    def calculate_single_ic_for_expr(self, expr: Expression) -> float:
        """è®¡ç®—å•ä¸ªè¡¨è¾¾å¼çš„ICï¼ˆç”¨äºæ‰¹å¤„ç†ï¼‰"""
        try:
            return self.calculator.calc_single_IC_ret(expr)
        except Exception as e:
            print(f"Error calculating IC for expression: {e}")
            return 0.0

    def _calc_ics(
        self,
        expr: Expression,
        ic_mut_threshold: Optional[float] = None
    ) -> Tuple[float, Optional[List[float]]]:
        single_ic = self.calculator.calc_single_IC_ret(expr)
        if not self._under_thres_alpha and single_ic < self.ic_lower_bound:
            return single_ic, None

        mutual_ics = []
        for i in range(self.size):
            mutual_ic = self.calculator.calc_mutual_IC(expr, self.exprs[i])
            if ic_mut_threshold is not None and mutual_ic > ic_mut_threshold:
                return single_ic, None
            mutual_ics.append(mutual_ic)

        return single_ic, mutual_ics

    def _add_factor(
        self,
        expr: Expression,
        ic_ret: float,
        ic_mut: List[float]
    ):
        if self._under_thres_alpha and self.size == 1:
            self._pop()
        n = self.size
        self.exprs[n] = expr
        self.single_ics[n] = ic_ret
        for i in range(n):
            self.mutual_ics[i][n] = self.mutual_ics[n][i] = ic_mut[i]
        self.weights[n] = ic_ret  # An arbitrary init value
        self.size += 1

    def _pop(self) -> None:
        if self.size <= self.capacity:
            return

        if self.culling_method == 'weight':
            # Original method: remove factor with smallest absolute weight
            worst_idx = np.argmin(np.abs(self.weights[:self.size]))
        elif self.culling_method == 'ic_drop':
            # Remove factor with smallest IC impact (least important)
            current_ic = self.evaluate_ensemble()
            min_ic_drop = float('inf')
            worst_idx = 0

            for i in range(self.size):
                # Temporarily remove factor i and calculate IC
                temp_size = self.size - 1
                if temp_size == 0:
                    continue

                temp_weights = np.delete(self.weights[:self.size], i)
                temp_exprs = [self.exprs[j] for j in range(self.size) if j != i]

                # Normalize weights
                if np.sum(np.abs(temp_weights)) > 0:
                    temp_weights = temp_weights / np.sum(np.abs(temp_weights))

                temp_ic = self.calculator.calc_pool_IC_ret(temp_exprs, temp_weights.tolist())
                ic_drop = current_ic - temp_ic

                if ic_drop < min_ic_drop:
                    min_ic_drop = ic_drop
                    worst_idx = i
        elif self.culling_method == 'combined':
            # Combined method: IC drop * weight importance
            current_ic = self.evaluate_ensemble()
            min_combined_score = float('inf')
            worst_idx = 0

            for i in range(self.size):
                temp_size = self.size - 1
                if temp_size == 0:
                    continue

                temp_weights = np.delete(self.weights[:self.size], i)
                temp_exprs = [self.exprs[j] for j in range(self.size) if j != i]

                if np.sum(np.abs(temp_weights)) > 0:
                    temp_weights = temp_weights / np.sum(np.abs(temp_weights))

                temp_ic = self.calculator.calc_pool_IC_ret(temp_exprs, temp_weights.tolist())
                ic_drop = current_ic - temp_ic
                weight_importance = abs(self.weights[i])

                # Combined score: smaller IC drop + smaller weight = more likely to be removed
                combined_score = ic_drop * (1.0 + weight_importance)

                if combined_score < min_combined_score:
                    min_combined_score = combined_score
                    worst_idx = i
        else:
            raise ValueError(f"Unknown culling method: {self.culling_method}")

        self._swap_idx(worst_idx, self.capacity)
        self.size = self.capacity

    def _swap_idx(self, i, j) -> None:
        if i == j:
            return
        self.exprs[i], self.exprs[j] = self.exprs[j], self.exprs[i]
        self.single_ics[i], self.single_ics[j] = self.single_ics[j], self.single_ics[i]
        self.mutual_ics[:, [i, j]] = self.mutual_ics[:, [j, i]]
        self.mutual_ics[[i, j], :] = self.mutual_ics[[j, i], :]
        self.weights[i], self.weights[j] = self.weights[j], self.weights[i]
        self.single_ics[i], self.single_ics[j] = self.single_ics[j], self.single_ics[i]
        self.mutual_ics[:, [i, j]] = self.mutual_ics[:, [j, i]]
        self.mutual_ics[[i, j], :] = self.mutual_ics[[j, i], :]
        self.weights[i], self.weights[j] = self.weights[j], self.weights[i]
        self.weights[i], self.weights[j] = self.weights[j], self.weights[i]
        self.weights[i], self.weights[j] = self.weights[j], self.weights[i]
        self.weights[i], self.weights[j] = self.weights[j], self.weights[i]
