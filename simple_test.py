import gymnasium as gym
import numpy as np
import random
from typing import List, Tuple

# ==========================================
# 1. èµ„æºåŠ è½½ (è¯»å–ä½ çš„é…ç½®)
# ==========================================
try:
    # å°è¯•å¯¼å…¥ä½ çš„çœŸå®é…ç½®
    from adapters.field_config import field_config
    FIELD_NAMES = field_config.get_field_names()
    from alphagen.config import OPERATORS
    print(f"ğŸ“š æˆåŠŸåŠ è½½é…ç½®: {len(FIELD_NAMES)} ä¸ªå­—æ®µ, {len(OPERATORS)} ä¸ªç®—å­")
except ImportError:
    # å…œåº•æ•°æ® (é˜²æ­¢æŠ¥é”™æ— æ³•è¿è¡Œ)
    print("âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨ Mock æ•°æ®æ¨¡å¼...")
    FIELD_NAMES = [f"close_{i}" for i in range(10)]
    class MockOp:
        def __init__(self, name, n_args): self.name, self._n = name, n_args
        def n_args(self): return self._n
        def __str__(self): return self.name
    OPERATORS = [MockOp("Add", 2), MockOp("Sub", 2), MockOp("Abs", 1), MockOp("Ts_Mean", 2)]

# ==========================================
# 2. æç®€ç¯å¢ƒå®šä¹‰
# ==========================================
class SimpleGenEnv(gym.Env):
    def __init__(self, max_steps=20, max_stack_depth=3):
        super().__init__()
        self.max_steps = max_steps
        self.max_stack_depth = max_stack_depth  # ğŸ”¥ æ–°å¢é™åˆ¶ï¼šæœ€å¤§å †æ ˆæ·±åº¦
        
        # --- åŠ¨ä½œç©ºé—´æ˜ å°„ ---
        self.ops = OPERATORS
        self.fields = FIELD_NAMES
        
        # ID åç§»é‡è®¾è®¡
        # [0...N_OP-1] -> ç®—å­
        # [N_OP...N_OP+N_FIELD-1] -> å­—æ®µ
        # [æœ€å] -> SEP
        self.offset_op = 0
        self.offset_field = len(self.ops)
        self.offset_sep = self.offset_field + len(self.fields)
        
        self.n_actions = self.offset_sep + 1
        
        # å®šä¹‰ Gym ç©ºé—´
        self.action_space = gym.spaces.Discrete(self.n_actions)
        # è§‚æµ‹ç©ºé—´ï¼šå›ºå®šé•¿åº¦çš„æ•´æ•°æ•°ç»„
        self.observation_space = gym.spaces.Box(
            low=0, high=self.n_actions, shape=(max_steps,), dtype=np.int32
        )
        
        # å†…éƒ¨çŠ¶æ€
        self.current_step_count = 0
        self.generated_ids = []   # è®°å½•ç”Ÿæˆçš„ token ID åºåˆ—
        self.stack_depth = 0      # æ ¸å¿ƒçŠ¶æ€ï¼šå½“å‰æ ˆé‡Œæœ‰å‡ ä¸ªå…ƒç´ 
        
    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.current_step_count = 0
        self.generated_ids = []
        self.stack_depth = 0
        return self._get_obs(), {}

    def step(self, action: int):
        # 1. è®°å½•åŠ¨ä½œ
        self.generated_ids.append(action)
        self.current_step_count += 1
        
        truncated = False
        terminated = False
        reward = 0.0
        info = {}

        # 2. è§£æåŠ¨ä½œå¹¶æ›´æ–°å †æ ˆçŠ¶æ€
        if action < self.offset_field:
            # ---> ç®—å­ (Operator)
            op = self.ops[action]
            n_args = op.n_args()
            # RPNé€»è¾‘ï¼šæ¶ˆè€— n ä¸ªå‚æ•°ï¼Œç”Ÿæˆ 1 ä¸ªç»“æœ
            # å‡€å˜åŒ– = 1 - n
            self.stack_depth -= (n_args - 1)
            
        elif action < self.offset_sep:
            # ---> å­—æ®µ (Feature)
            # å‹æ ˆï¼Œæ·±åº¦ +1
            self.stack_depth += 1
            
        elif action == self.offset_sep:
            # ---> SEP (åœæ­¢)
            terminated = True
            reward = 1.0 # æˆåŠŸç”Ÿæˆå¥–åŠ±
            
        else:
            # å¼‚å¸¸æƒ…å†µ
            truncated = True
            reward = -1.0
            
        # 3. é•¿åº¦æ£€æŸ¥ (è¶…è¿‡20æ­¥å¼ºåˆ¶æˆªæ–­)
        if self.current_step_count >= self.max_steps:
            truncated = True
            if not terminated:
                info['reason'] = 'max_steps_reached'
        
        # 4. è¿”å›
        return self._get_obs(), reward, terminated, truncated, info

    def action_masks(self) -> np.ndarray:
        """
        ğŸ”¥ æ ¸å¿ƒé€»è¾‘ï¼šå†³å®šå“ªäº›åŠ¨ä½œç°åœ¨èƒ½é€‰
        """
        mask = np.zeros(self.n_actions, dtype=bool)
        
        # --- Rule 1: å­—æ®µ (Feature) ---
        # åªæœ‰åœ¨æ ˆæ·±åº¦è¿˜æ²¡æ»¡çš„æ—¶å€™ï¼Œæ‰å…è®¸åŠ å­—æ®µ
        # è¿™å°±æ˜¯ä½ è¦çš„ï¼šå‡å¦‚å·²ç»æœ‰3ä¸ªéƒ¨åˆ†äº†(stack_depth >= 3)ï¼Œè¿™é‡Œå°±ä¼šæ˜¯ False
        if self.stack_depth < self.max_stack_depth:
            mask[self.offset_field : self.offset_sep] = True
            
        # --- Rule 2: ç®—å­ (Operator) ---
        # åªæœ‰æ ˆé‡Œçš„æ•°è¶³å¤Ÿç®—å­åƒçš„æ—¶å€™ï¼Œæ‰å…è®¸é€‰
        # ä¾‹å¦‚ï¼šAdd éœ€è¦ 2 ä¸ªæ•°ï¼Œåªæœ‰ stack_depth >= 2 æ‰èƒ½é€‰ Add
        for i, op in enumerate(self.ops):
            if self.stack_depth >= op.n_args():
                mask[i] = True
                
        # --- Rule 3: åœæ­¢ç¬¦ (SEP) ---
        # åªæœ‰æ ˆé‡Œå‰© 1 ä¸ªå®Œæ•´ç»“æœï¼Œä¸”ä¸æ˜¯ç¬¬ 0 æ­¥æ—¶ï¼Œæ‰å…è®¸åœ
        if self.stack_depth == 1 and self.current_step_count > 0:
            mask[self.offset_sep] = True
            
        return mask

    def _get_obs(self):
        # è‡ªåŠ¨ Padding åˆ°å›ºå®šé•¿åº¦ï¼Œä¿è¯ Agent ä¸æŠ¥é”™
        obs = np.array(self.generated_ids, dtype=np.int32)
        if len(obs) < self.max_steps:
            padding = np.zeros(self.max_steps - len(obs), dtype=np.int32)
            obs = np.concatenate([obs, padding])
        return obs[:self.max_steps]

    def decode_expression(self):
        """Debug ç”¨ï¼šæŠŠ ID ç¿»è¯‘æˆäººè¯"""
        res = []
        for a in self.generated_ids:
            if a < self.offset_field:
                res.append(f"Op({self.ops[a]})")
            elif a < self.offset_sep:
                res.append(f"Field({self.fields[a - self.offset_field]})")
            elif a == self.offset_sep:
                res.append("SEP")
        return " -> ".join(res)

# ==========================================
# 3. éªŒè¯æµ‹è¯•
# ==========================================
if __name__ == "__main__":
    print("\nğŸš€ å¯åŠ¨çº¯å‡€ç‰ˆç”Ÿæˆå™¨ (Max Depth=3 æµ‹è¯•)")
    env = SimpleGenEnv(max_steps=20, max_stack_depth=2)
    
    for i in range(5):
        print(f"\nğŸ¬ Episode {i+1}:")
        obs, _ = env.reset()
        done = False
        
        while not done:
            # 1. è·å– Mask
            mask = env.action_masks()
            valid_indices = np.where(mask)[0]
            
            if len(valid_indices) == 0:
                print("âŒ æ­»å±€ (æ— åˆæ³•åŠ¨ä½œ)")
                break
            
            # 2. éšæœºé‡‡æ ·
            action = np.random.choice(valid_indices)
            
            # 3. æ‰§è¡Œ
            obs, reward, term, trunc, info = env.step(action)
            done = term or trunc
            
            # æ‰“å°å½“å‰çŠ¶æ€
            stack_status = "ğŸŸ¥ æ»¡" if env.stack_depth >= 3 else f"{env.stack_depth}"
            print(f"  Step {env.current_step_count:2d} | æ ˆæ·±: {stack_status} | åŠ¨ä½œID: {action}")

        print(f"  ğŸ“ ç»“æœ: {env.decode_expression()}")
        if trunc: print("  âš ï¸  è§¦å‘æˆªæ–­ (è¿‡é•¿)")
        if term:  print("  âœ…  æˆåŠŸç”Ÿæˆ")